{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprojectioning: \n",
    "1. climate precipitation\n",
    "2. gridded population density\n",
    "3. land cover\n",
    "\n",
    "to GPP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('Datasets_Hackathon/MODIS_Gross_Primary_Production_GPP/2010_GP.tif') as src_GPP:\n",
    "    with rasterio.open('Datasets_Hackathon/Climate_Precipitation_Data/2010R.tif') as src_climate:\n",
    "        \n",
    "        # 2. Choose which dataset to use as the reference (target)\n",
    "        # Usually you'd choose the higher resolution one\n",
    "        # For this example, let's use landcover as the reference\n",
    "        \n",
    "        # Get the metadata from the reference file\n",
    "        dst_crs = src_GPP.crs\n",
    "        dst_transform = src_GPP.transform\n",
    "        dst_height = src_GPP.height\n",
    "        dst_width = src_GPP.width\n",
    "        \n",
    "        # 3. Create a destination array for the reprojected climate data\n",
    "        dst_climate = np.zeros((dst_height, dst_width), dtype=rasterio.float32)\n",
    "        \n",
    "        # 4. Reproject the climate data to match the landcover data\n",
    "        reproject(\n",
    "            source=rasterio.band(src_climate, 1),\n",
    "            destination=dst_climate,\n",
    "            src_transform=src_climate.transform,\n",
    "            src_crs=src_climate.crs,\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.bilinear  # Choose appropriate resampling method\n",
    "        )\n",
    "        \n",
    "        # 5. Now dst_climate and src_landcover.read(1) should be aligned\n",
    "        GPP_data = src_GPP.read(1)\n",
    "        \n",
    "        # 6. Now you can extract and compare data for the same pixels\n",
    "        # For example, to get pixel values at position (100, 100):\n",
    "        gpp_value = GPP_data[100, 100]\n",
    "        climate_value = dst_climate[100, 100]\n",
    "        \n",
    "        print(f\"Land cover value: {gpp_value}\")\n",
    "        print(f\"Climate value: {climate_value}\")\n",
    "        \n",
    "        # 7. Optional: Save the reprojected climate data\n",
    "        profile = src_GPP.profile.copy()\n",
    "        profile.update(dtype=rasterio.float32, count=1)\n",
    "        \n",
    "        with rasterio.open('climate_reprojected.tif', 'w', **profile) as dst:\n",
    "            dst.write(dst_climate, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for year 2010...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2010.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2010.tif\n",
      "Processing data for year 2011...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2011.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2011.tif\n",
      "Processing data for year 2012...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2012.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2012.tif\n",
      "Processing data for year 2013...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2013.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2013.tif\n",
      "Processing data for year 2014...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2014.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2014.tif\n",
      "Processing data for year 2015...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2015.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2015.tif\n",
      "Processing data for year 2016...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2016.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2016.tif\n",
      "Processing data for year 2017...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2017.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2017.tif\n",
      "Processing data for year 2018...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2018.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2018.tif\n",
      "Processing data for year 2019...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2019.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2019.tif\n",
      "Processing data for year 2020...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2020.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2020.tif\n",
      "Processing data for year 2021...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2021.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2021.tif\n",
      "Processing data for year 2022...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2022.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2022.tif\n"
     ]
    }
   ],
   "source": [
    "# Define years list\n",
    "years = range(2010, 2023)\n",
    "\n",
    "# Define input and output paths\n",
    "data_path = 'Datasets_Hackathon'\n",
    "output_path = 'Datasets_Hackathon/reprojected_data'  # Current directory, change as needed\n",
    "\n",
    "# List of data categories with their appropriate resampling methods and filename formats\n",
    "datasets = [\n",
    "    {'name': 'MODIS_Gross_Primary_Production_GPP', 'file_format': '{year}_GP.tif', 'is_reference': True},\n",
    "    {'name': 'Climate_Precipitation_Data', 'file_format': '{year}R.tif', 'resampling': Resampling.bilinear}, #Resampling.bilinear\n",
    "    {'name': 'Modis_Land_Cover_Data', 'file_format': '{year}LCT.tif', 'resampling': Resampling.nearest},\n",
    "    # {'name': 'Gridded_Population_Density_Data', 'file_format': 'Assaba_Pop_{year}.tif', 'resampling': Resampling.bilinear}\n",
    "]\n",
    "\n",
    "# Dictionary to store data for all years and all datasets\n",
    "all_data = {}\n",
    "for dataset in datasets:\n",
    "    short_name = dataset['name'].split('_')[0].lower()\n",
    "    all_data[short_name] = {}\n",
    "\n",
    "# Loop through each year\n",
    "for year in years:\n",
    "    print(f\"Processing data for year {year}...\")\n",
    "    \n",
    "    # First, open the reference dataset (GPP)\n",
    "    ref_dataset = next(d for d in datasets if d['is_reference'])\n",
    "    ref_file = os.path.join(data_path, ref_dataset['name'], ref_dataset['file_format'].format(year=year))\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(ref_file) as src_ref:\n",
    "            # Get reference metadata\n",
    "            dst_crs = src_ref.crs\n",
    "            dst_transform = src_ref.transform\n",
    "            dst_height = src_ref.height\n",
    "            dst_width = src_ref.width\n",
    "            \n",
    "            # Read reference data (GPP)\n",
    "            gpp_data = src_ref.read(1)\n",
    "            all_data['modis'][year] = gpp_data\n",
    "            \n",
    "            # Store reference profile for output files\n",
    "            profile = src_ref.profile.copy()\n",
    "            profile.update(dtype=rasterio.float32, count=1)\n",
    "            \n",
    "            # Process each non-reference dataset\n",
    "            for dataset in [d for d in datasets if not d.get('is_reference', False)]:\n",
    "                dataset_name = dataset['name'].split('_')[0].lower()  # Extract short name\n",
    "                \n",
    "                # Construct input filename using the file format template\n",
    "                input_file = os.path.join(data_path, dataset['name'], dataset['file_format'].format(year=year))\n",
    "                output_file = os.path.join(output_path, f\"{dataset_name}_reprojected_{year}.tif\")\n",
    "                \n",
    "                # Create destination array\n",
    "                dst_array = np.zeros((dst_height, dst_width), dtype=rasterio.float32)\n",
    "                \n",
    "                # Open and reproject\n",
    "                try:\n",
    "                    with rasterio.open(input_file) as src:\n",
    "                        reproject(\n",
    "                            source=rasterio.band(src, 1),\n",
    "                            destination=dst_array,\n",
    "                            src_transform=src.transform,\n",
    "                            src_crs=src.crs,\n",
    "                            dst_transform=dst_transform,\n",
    "                            dst_crs=dst_crs,\n",
    "                            resampling=dataset['resampling']\n",
    "                        )\n",
    "                        \n",
    "                        # Store in all_data dictionary by year\n",
    "                        all_data[dataset_name][year] = dst_array\n",
    "                        \n",
    "                        # Save reprojected data\n",
    "                        with rasterio.open(output_file, 'w', **profile) as dst:\n",
    "                            dst.write(dst_array, 1)\n",
    "                            \n",
    "                        print(f\"Successfully reprojected and saved {output_file}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {input_file}: {e}\")\n",
    "                    continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing year {year}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and testing arrays construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid samples across all years: 163955\n",
      "Added 163955 samples for year 2010\n",
      "Added 163955 samples for year 2011\n",
      "Added 163955 samples for year 2012\n",
      "Added 163955 samples for year 2013\n",
      "Added 163955 samples for year 2014\n",
      "Added 163955 samples for year 2015\n",
      "Added 163955 samples for year 2016\n",
      "Added 163955 samples for year 2017\n",
      "Added 163955 samples for year 2018\n",
      "Added 163955 samples for year 2019\n",
      "Added 163955 samples for year 2020\n",
      "Added 163955 samples for year 2021\n",
      "Added 163955 samples for year 2022\n",
      "Data preparation complete!\n",
      "Feature array shape: (2131415, 2)\n",
      "Target array shape: (2131415,)\n",
      "CSV data shape: (2131415, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create X and Y arrays for all years combined\n",
    "\n",
    "# First, determine valid pixels across all datasets and years\n",
    "valid_mask = np.ones((dst_height, dst_width), dtype=bool)\n",
    "for dataset_name, years_data in all_data.items():\n",
    "    for year, data in years_data.items():\n",
    "        # Update mask for invalid values (assuming NaN or negative values are invalid)\n",
    "        if np.issubdtype(data.dtype, np.floating):\n",
    "            valid_mask = valid_mask & ~np.isnan(data)\n",
    "        valid_mask = valid_mask & (data >= 0)\n",
    "\n",
    "# Count how many valid samples we'll have\n",
    "n_samples = np.sum(valid_mask)\n",
    "print(f\"Total valid samples across all years: {n_samples}\")\n",
    "\n",
    "# Create X (features) and Y (target) arrays\n",
    "n_years = len(years)\n",
    "n_features = len([d for d in datasets if not d.get('is_reference', False)])\n",
    "X = np.zeros((n_samples * n_years, n_features))\n",
    "Y = np.zeros(n_samples * n_years)\n",
    "\n",
    "# Create a dataframe to store the data\n",
    "columns = ['year', 'row', 'col', 'gpp']\n",
    "for dataset in [d for d in datasets if not d.get('is_reference', False)]:\n",
    "    short_name = dataset['name'].split('_')[0].lower()\n",
    "    columns.append(short_name)\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Fill the dataframe\n",
    "sample_idx = 0\n",
    "for year_idx, year in enumerate(years):\n",
    "    # Get valid coordinates\n",
    "    rows, cols = np.where(valid_mask)\n",
    "    \n",
    "    # Temporary data for this year\n",
    "    year_data = []\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        row, col = rows[i], cols[i]\n",
    "        \n",
    "        # Skip if any dataset has invalid data for this pixel in this year\n",
    "        skip = False\n",
    "        for dataset_name, years_data in all_data.items():\n",
    "            if year not in years_data or np.isnan(years_data[year][row, col]):\n",
    "                skip = True\n",
    "                break\n",
    "        if skip:\n",
    "            continue\n",
    "            \n",
    "        # Create a row in the dataframe\n",
    "        row_data = {\n",
    "            'year': year,\n",
    "            'row': row,\n",
    "            'col': col,\n",
    "            'gpp': all_data['modis'][year][row, col]\n",
    "        }\n",
    "        \n",
    "        # Add feature data\n",
    "        feature_idx = 0\n",
    "        for dataset in [d for d in datasets if not d.get('is_reference', False)]:\n",
    "            short_name = dataset['name'].split('_')[0].lower()\n",
    "            row_data[short_name] = all_data[short_name][year][row, col]\n",
    "            # Also add to X array\n",
    "            X[sample_idx, feature_idx] = all_data[short_name][year][row, col]\n",
    "            feature_idx += 1\n",
    "        \n",
    "        # Add to Y array\n",
    "        Y[sample_idx] = all_data['modis'][year][row, col]\n",
    "        \n",
    "        # Add to temporary data\n",
    "        year_data.append(row_data)\n",
    "        \n",
    "        sample_idx += 1\n",
    "    \n",
    "    # Add this year's data to the dataframe\n",
    "    df = pd.concat([df, pd.DataFrame(year_data)], ignore_index=True)\n",
    "    print(f\"Added {len(year_data)} samples for year {year}\")\n",
    "\n",
    "# Trim excess rows if needed\n",
    "if sample_idx < n_samples * n_years:\n",
    "    X = X[:sample_idx, :]\n",
    "    Y = Y[:sample_idx]\n",
    "    print(f\"Trimmed arrays to actual size: {sample_idx} samples\")\n",
    "\n",
    "# Save the prepared data\n",
    "df.to_csv('all_data_prepared.csv', index=False)\n",
    "np.save('X_features.npy', X)\n",
    "np.save('Y_target.npy', Y)\n",
    "\n",
    "print(\"Data preparation complete!\")\n",
    "print(f\"Feature array shape: {X.shape}\")\n",
    "print(f\"Target array shape: {Y.shape}\")\n",
    "print(f\"CSV data shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>gpp</th>\n",
       "      <th>climate</th>\n",
       "      <th>modis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>459</td>\n",
       "      <td>16.0</td>\n",
       "      <td>122.910858</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>460</td>\n",
       "      <td>16.0</td>\n",
       "      <td>122.601082</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>461</td>\n",
       "      <td>16.0</td>\n",
       "      <td>122.291298</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>457</td>\n",
       "      <td>16.0</td>\n",
       "      <td>123.511665</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>458</td>\n",
       "      <td>16.0</td>\n",
       "      <td>123.201889</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131410</th>\n",
       "      <td>2022</td>\n",
       "      <td>758</td>\n",
       "      <td>451</td>\n",
       "      <td>10.0</td>\n",
       "      <td>549.432678</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131411</th>\n",
       "      <td>2022</td>\n",
       "      <td>758</td>\n",
       "      <td>452</td>\n",
       "      <td>10.0</td>\n",
       "      <td>550.221802</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131412</th>\n",
       "      <td>2022</td>\n",
       "      <td>758</td>\n",
       "      <td>453</td>\n",
       "      <td>10.0</td>\n",
       "      <td>551.010925</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131413</th>\n",
       "      <td>2022</td>\n",
       "      <td>758</td>\n",
       "      <td>454</td>\n",
       "      <td>10.0</td>\n",
       "      <td>551.80011</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131414</th>\n",
       "      <td>2022</td>\n",
       "      <td>758</td>\n",
       "      <td>455</td>\n",
       "      <td>10.0</td>\n",
       "      <td>552.589233</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2131415 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  row  col   gpp     climate modis\n",
       "0        2010    3  459  16.0  122.910858  16.0\n",
       "1        2010    3  460  16.0  122.601082  16.0\n",
       "2        2010    3  461  16.0  122.291298  16.0\n",
       "3        2010    4  457  16.0  123.511665  16.0\n",
       "4        2010    4  458  16.0  123.201889  16.0\n",
       "...       ...  ...  ...   ...         ...   ...\n",
       "2131410  2022  758  451  10.0  549.432678  10.0\n",
       "2131411  2022  758  452  10.0  550.221802  10.0\n",
       "2131412  2022  758  453  10.0  551.010925  10.0\n",
       "2131413  2022  758  454  10.0   551.80011  10.0\n",
       "2131414  2022  758  455  10.0  552.589233  10.0\n",
       "\n",
       "[2131415 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['climate', 'modis']].values\n",
    "y = df['gpp'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_categorical = y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/9q5q5y114zj360801_hx11rc0000gn/T/ipykernel_90854/1731800309.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'modis'] = X['modis'].astype('category')\n"
     ]
    }
   ],
   "source": [
    "X.loc[:, 'modis'] = X['modis'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/9q5q5y114zj360801_hx11rc0000gn/T/ipykernel_90854/2011796791.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['modis'] = label_encoder.fit_transform(X['modis'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R-squared (Accuracy) on test set: 0.9987221500825927\n"
     ]
    }
   ],
   "source": [
    "# Convert 'modis' into categorical using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "X['modis'] = label_encoder.fit_transform(X['modis'])\n",
    "\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Model R-squared (Accuracy) on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
