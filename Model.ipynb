{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprojectioning: \n",
    "1. climate precipitation\n",
    "2. gridded population density\n",
    "3. land cover\n",
    "\n",
    "to GPP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('Datasets_Hackathon/MODIS_Gross_Primary_Production_GPP/2010_GP.tif') as src_GPP:\n",
    "    with rasterio.open('Datasets_Hackathon/Climate_Precipitation_Data/2010R.tif') as src_climate:\n",
    "        \n",
    "        # 2. Choose which dataset to use as the reference (target)\n",
    "        # Usually you'd choose the higher resolution one\n",
    "        # For this example, let's use landcover as the reference\n",
    "        \n",
    "        # Get the metadata from the reference file\n",
    "        dst_crs = src_GPP.crs\n",
    "        dst_transform = src_GPP.transform\n",
    "        dst_height = src_GPP.height\n",
    "        dst_width = src_GPP.width\n",
    "        \n",
    "        # 3. Create a destination array for the reprojected climate data\n",
    "        dst_climate = np.zeros((dst_height, dst_width), dtype=rasterio.float32)\n",
    "        \n",
    "        # 4. Reproject the climate data to match the landcover data\n",
    "        reproject(\n",
    "            source=rasterio.band(src_climate, 1),\n",
    "            destination=dst_climate,\n",
    "            src_transform=src_climate.transform,\n",
    "            src_crs=src_climate.crs,\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.bilinear  # Choose appropriate resampling method\n",
    "        )\n",
    "        \n",
    "        # 5. Now dst_climate and src_landcover.read(1) should be aligned\n",
    "        GPP_data = src_GPP.read(1)\n",
    "        \n",
    "        # 6. Now you can extract and compare data for the same pixels\n",
    "        # For example, to get pixel values at position (100, 100):\n",
    "        gpp_value = GPP_data[100, 100]\n",
    "        climate_value = dst_climate[100, 100]\n",
    "        \n",
    "        print(f\"Land cover value: {gpp_value}\")\n",
    "        print(f\"Climate value: {climate_value}\")\n",
    "        \n",
    "        # 7. Optional: Save the reprojected climate data\n",
    "        profile = src_GPP.profile.copy()\n",
    "        profile.update(dtype=rasterio.float32, count=1)\n",
    "        \n",
    "        with rasterio.open('climate_reprojected.tif', 'w', **profile) as dst:\n",
    "            dst.write(dst_climate, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for year 2010...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2010.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2010.tif\n",
      "Processing data for year 2011...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2011.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2011.tif\n",
      "Processing data for year 2012...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2012.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2012.tif\n",
      "Processing data for year 2013...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2013.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2013.tif\n",
      "Processing data for year 2014...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2014.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2014.tif\n",
      "Processing data for year 2015...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2015.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2015.tif\n",
      "Processing data for year 2016...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2016.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2016.tif\n",
      "Processing data for year 2017...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2017.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2017.tif\n",
      "Processing data for year 2018...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2018.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2018.tif\n",
      "Processing data for year 2019...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2019.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2019.tif\n",
      "Processing data for year 2020...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2020.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2020.tif\n",
      "Processing data for year 2021...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2021.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2021.tif\n",
      "Processing data for year 2022...\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/climate_reprojected_2022.tif\n",
      "Successfully reprojected and saved Datasets_Hackathon/reprojected_data/modis_reprojected_2022.tif\n"
     ]
    }
   ],
   "source": [
    "# Define years list\n",
    "years = range(2010, 2023)\n",
    "\n",
    "# Define input and output paths\n",
    "data_path = 'Datasets_Hackathon'\n",
    "output_path = 'Datasets_Hackathon/reprojected_data'  # Current directory, change as needed\n",
    "\n",
    "# List of data categories with their appropriate resampling methods and filename formats\n",
    "datasets = [\n",
    "    {'name': 'MODIS_Gross_Primary_Production_GPP', 'file_format': '{year}_GP.tif', 'is_reference': True},\n",
    "    {'name': 'Climate_Precipitation_Data', 'file_format': '{year}R.tif', 'resampling': Resampling.bilinear}, #Resampling.bilinear\n",
    "    {'name': 'Modis_Land_Cover_Data', 'file_format': '{year}LCT.tif', 'resampling': Resampling.nearest},\n",
    "    # {'name': 'Gridded_Population_Density_Data', 'file_format': 'Assaba_Pop_{year}.tif', 'resampling': Resampling.bilinear}\n",
    "]\n",
    "\n",
    "# Dictionary to store data for all years and all datasets\n",
    "all_data = {}\n",
    "for dataset in datasets:\n",
    "    short_name = dataset['name'].split('_')[0].lower()\n",
    "    all_data[short_name] = {}\n",
    "\n",
    "# Loop through each year\n",
    "for year in years:\n",
    "    print(f\"Processing data for year {year}...\")\n",
    "    \n",
    "    # First, open the reference dataset (GPP)\n",
    "    ref_dataset = next(d for d in datasets if d['is_reference'])\n",
    "    ref_file = os.path.join(data_path, ref_dataset['name'], ref_dataset['file_format'].format(year=year))\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(ref_file) as src_ref:\n",
    "            # Get reference metadata\n",
    "            dst_crs = src_ref.crs\n",
    "            dst_transform = src_ref.transform\n",
    "            dst_height = src_ref.height\n",
    "            dst_width = src_ref.width\n",
    "            \n",
    "            # Read reference data (GPP)\n",
    "            gpp_data = src_ref.read(1)\n",
    "            all_data['modis'][year] = gpp_data\n",
    "            \n",
    "            # Store reference profile for output files\n",
    "            profile = src_ref.profile.copy()\n",
    "            profile.update(dtype=rasterio.float32, count=1)\n",
    "            \n",
    "            # Process each non-reference dataset\n",
    "            for dataset in [d for d in datasets if not d.get('is_reference', False)]:\n",
    "                dataset_name = dataset['name'].split('_')[0].lower()  # Extract short name\n",
    "                \n",
    "                # Construct input filename using the file format template\n",
    "                input_file = os.path.join(data_path, dataset['name'], dataset['file_format'].format(year=year))\n",
    "                output_file = os.path.join(output_path, f\"{dataset_name}_reprojected_{year}.tif\")\n",
    "                \n",
    "                # Create destination array\n",
    "                dst_array = np.zeros((dst_height, dst_width), dtype=rasterio.float32)\n",
    "                \n",
    "                # Open and reproject\n",
    "                try:\n",
    "                    with rasterio.open(input_file) as src:\n",
    "                        reproject(\n",
    "                            source=rasterio.band(src, 1),\n",
    "                            destination=dst_array,\n",
    "                            src_transform=src.transform,\n",
    "                            src_crs=src.crs,\n",
    "                            dst_transform=dst_transform,\n",
    "                            dst_crs=dst_crs,\n",
    "                            resampling=dataset['resampling']\n",
    "                        )\n",
    "                        \n",
    "                        # Store in all_data dictionary by year\n",
    "                        all_data[dataset_name][year] = dst_array\n",
    "                        \n",
    "                        # Save reprojected data\n",
    "                        with rasterio.open(output_file, 'w', **profile) as dst:\n",
    "                            dst.write(dst_array, 1)\n",
    "                            \n",
    "                        print(f\"Successfully reprojected and saved {output_file}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {input_file}: {e}\")\n",
    "                    continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing year {year}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and testing arrays construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid samples across all years: 163955\n",
      "Added 163955 samples for year 2010\n",
      "Added 163955 samples for year 2011\n",
      "Added 163955 samples for year 2012\n",
      "Added 163955 samples for year 2013\n",
      "Added 163955 samples for year 2014\n",
      "Added 163955 samples for year 2015\n",
      "Added 163955 samples for year 2016\n",
      "Added 163955 samples for year 2017\n",
      "Added 163955 samples for year 2018\n",
      "Added 163955 samples for year 2019\n",
      "Added 163955 samples for year 2020\n",
      "Added 163955 samples for year 2021\n",
      "Added 163955 samples for year 2022\n",
      "Data preparation complete!\n",
      "Feature array shape: (2131415, 2)\n",
      "Target array shape: (2131415,)\n",
      "CSV data shape: (2131415, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create X and Y arrays for all years combined\n",
    "\n",
    "# First, determine valid pixels across all datasets and years\n",
    "valid_mask = np.ones((dst_height, dst_width), dtype=bool)\n",
    "for dataset_name, years_data in all_data.items():\n",
    "    for year, data in years_data.items():\n",
    "        # Update mask for invalid values (assuming NaN or negative values are invalid)\n",
    "        if np.issubdtype(data.dtype, np.floating):\n",
    "            valid_mask = valid_mask & ~np.isnan(data)\n",
    "        valid_mask = valid_mask & (data >= 0)\n",
    "\n",
    "# Count how many valid samples we'll have\n",
    "n_samples = np.sum(valid_mask)\n",
    "print(f\"Total valid samples across all years: {n_samples}\")\n",
    "\n",
    "# Create X (features) and Y (target) arrays\n",
    "n_years = len(years)\n",
    "n_features = len([d for d in datasets if not d.get('is_reference', False)])\n",
    "X = np.zeros((n_samples * n_years, n_features))\n",
    "Y = np.zeros(n_samples * n_years)\n",
    "\n",
    "# Create a dataframe to store the data\n",
    "columns = ['year', 'row', 'col', 'gpp']\n",
    "for dataset in [d for d in datasets if not d.get('is_reference', False)]:\n",
    "    short_name = dataset['name'].split('_')[0].lower()\n",
    "    columns.append(short_name)\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Fill the dataframe\n",
    "sample_idx = 0\n",
    "for year_idx, year in enumerate(years):\n",
    "    # Get valid coordinates\n",
    "    rows, cols = np.where(valid_mask)\n",
    "    \n",
    "    # Temporary data for this year\n",
    "    year_data = []\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        row, col = rows[i], cols[i]\n",
    "        \n",
    "        # Skip if any dataset has invalid data for this pixel in this year\n",
    "        skip = False\n",
    "        for dataset_name, years_data in all_data.items():\n",
    "            if year not in years_data or np.isnan(years_data[year][row, col]):\n",
    "                skip = True\n",
    "                break\n",
    "        if skip:\n",
    "            continue\n",
    "            \n",
    "        # Create a row in the dataframe\n",
    "        row_data = {\n",
    "            'year': year,\n",
    "            'row': row,\n",
    "            'col': col,\n",
    "            'gpp': all_data['modis'][year][row, col]\n",
    "        }\n",
    "        \n",
    "        # Add feature data\n",
    "        feature_idx = 0\n",
    "        for dataset in [d for d in datasets if not d.get('is_reference', False)]:\n",
    "            short_name = dataset['name'].split('_')[0].lower()\n",
    "            row_data[short_name] = all_data[short_name][year][row, col]\n",
    "            # Also add to X array\n",
    "            X[sample_idx, feature_idx] = all_data[short_name][year][row, col]\n",
    "            feature_idx += 1\n",
    "        \n",
    "        # Add to Y array\n",
    "        Y[sample_idx] = all_data['modis'][year][row, col]\n",
    "        \n",
    "        # Add to temporary data\n",
    "        year_data.append(row_data)\n",
    "        \n",
    "        sample_idx += 1\n",
    "    \n",
    "    # Add this year's data to the dataframe\n",
    "    df = pd.concat([df, pd.DataFrame(year_data)], ignore_index=True)\n",
    "    print(f\"Added {len(year_data)} samples for year {year}\")\n",
    "\n",
    "# Trim excess rows if needed\n",
    "if sample_idx < n_samples * n_years:\n",
    "    X = X[:sample_idx, :]\n",
    "    Y = Y[:sample_idx]\n",
    "    print(f\"Trimmed arrays to actual size: {sample_idx} samples\")\n",
    "\n",
    "# Save the prepared data\n",
    "df.to_csv('all_data_prepared.csv', index=False)\n",
    "np.save('X_features.npy', X)\n",
    "np.save('Y_target.npy', Y)\n",
    "\n",
    "print(\"Data preparation complete!\")\n",
    "print(f\"Feature array shape: {X.shape}\")\n",
    "print(f\"Target array shape: {Y.shape}\")\n",
    "print(f\"CSV data shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>gpp</th>\n",
       "      <th>climate</th>\n",
       "      <th>modis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>459</td>\n",
       "      <td>16.0</td>\n",
       "      <td>122.910858</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>460</td>\n",
       "      <td>16.0</td>\n",
       "      <td>122.601082</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>461</td>\n",
       "      <td>16.0</td>\n",
       "      <td>122.291298</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>457</td>\n",
       "      <td>16.0</td>\n",
       "      <td>123.511665</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>458</td>\n",
       "      <td>16.0</td>\n",
       "      <td>123.201889</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131410</th>\n",
       "      <td>2022</td>\n",
       "      <td>758</td>\n",
       "      <td>451</td>\n",
       "      <td>10.0</td>\n",
       "      <td>549.432678</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131411</th>\n",
       "      <td>2022</td>\n",
       "      <td>758</td>\n",
       "      <td>452</td>\n",
       "      <td>10.0</td>\n",
       "      <td>550.221802</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131412</th>\n",
       "      <td>2022</td>\n",
       "      <td>758</td>\n",
       "      <td>453</td>\n",
       "      <td>10.0</td>\n",
       "      <td>551.010925</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131413</th>\n",
       "      <td>2022</td>\n",
       "      <td>758</td>\n",
       "      <td>454</td>\n",
       "      <td>10.0</td>\n",
       "      <td>551.80011</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131414</th>\n",
       "      <td>2022</td>\n",
       "      <td>758</td>\n",
       "      <td>455</td>\n",
       "      <td>10.0</td>\n",
       "      <td>552.589233</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2131415 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  row  col   gpp     climate modis\n",
       "0        2010    3  459  16.0  122.910858  16.0\n",
       "1        2010    3  460  16.0  122.601082  16.0\n",
       "2        2010    3  461  16.0  122.291298  16.0\n",
       "3        2010    4  457  16.0  123.511665  16.0\n",
       "4        2010    4  458  16.0  123.201889  16.0\n",
       "...       ...  ...  ...   ...         ...   ...\n",
       "2131410  2022  758  451  10.0  549.432678  10.0\n",
       "2131411  2022  758  452  10.0  550.221802  10.0\n",
       "2131412  2022  758  453  10.0  551.010925  10.0\n",
       "2131413  2022  758  454  10.0   551.80011  10.0\n",
       "2131414  2022  758  455  10.0  552.589233  10.0\n",
       "\n",
       "[2131415 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['climate', 'modis']].values\n",
    "y = df['gpp'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_categorical = y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/9q5q5y114zj360801_hx11rc0000gn/T/ipykernel_90854/1731800309.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'modis'] = X['modis'].astype('category')\n"
     ]
    }
   ],
   "source": [
    "X.loc[:, 'modis'] = X['modis'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/9q5q5y114zj360801_hx11rc0000gn/T/ipykernel_90854/2011796791.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['modis'] = label_encoder.fit_transform(X['modis'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R-squared (Accuracy) on test set: 0.9987221500825927\n"
     ]
    }
   ],
   "source": [
    "# Convert 'modis' into categorical using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "X['modis'] = label_encoder.fit_transform(X['modis'])\n",
    "\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Model R-squared (Accuracy) on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Plotting y ('gpp') against the 'climate' feature\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclimate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScatter plot of GPP vs Climate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClimate Precipitation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py:46\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass the following variable\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mkeyword arg\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom version 0.12, the only valid positional argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py:2243\u001b[0m, in \u001b[0;36mboxplot\u001b[0;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth, whis, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[1;32m   2232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mboxplot\u001b[39m(\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2240\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2241\u001b[0m ):\n\u001b[0;32m-> 2243\u001b[0m     plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_BoxPlotter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m                          \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdodge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfliersize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2248\u001b[0m         ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py:406\u001b[0m, in \u001b[0;36m_BoxPlotter.__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[1;32m    403\u001b[0m              orient, color, palette, saturation,\n\u001b[1;32m    404\u001b[0m              width, dodge, fliersize, linewidth):\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestablish_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdodge \u001b[38;5;241m=\u001b[39m dodge\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py:206\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    203\u001b[0m group_names \u001b[38;5;241m=\u001b[39m categorical_order(groups, order)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Group the numeric data\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m plot_data, value_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_group_longform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mgroup_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Now handle the hue levels for nested ordering\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py:257\u001b[0m, in \u001b[0;36m_CategoricalPlotter._group_longform\u001b[0;34m(self, vals, grouper, order)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m order:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 257\u001b[0m         g_vals \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped_vals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m         g_vals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:749\u001b[0m, in \u001b[0;36mBaseGroupBy.get_group\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inds):\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(name)\n\u001b[0;32m--> 749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:922\u001b[0m, in \u001b[0;36mSeries._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 922\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:910\u001b[0m, in \u001b[0;36mSeries.take\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m    907\u001b[0m new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtake(indices)\n\u001b[1;32m    908\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mtake(indices)\n\u001b[0;32m--> 910\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfastpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:460\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    457\u001b[0m             data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n\u001b[1;32m    459\u001b[0m NDFrame\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_axis(\u001b[38;5;241m0\u001b[39m, index, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:5587\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5582\u001b[0m \u001b[38;5;66;03m# first try regular attribute access via __getattribute__, so that\u001b[39;00m\n\u001b[1;32m   5583\u001b[0m \u001b[38;5;66;03m# e.g. ``obj.x`` and ``obj.x = 4`` will always reference/modify\u001b[39;00m\n\u001b[1;32m   5584\u001b[0m \u001b[38;5;66;03m# the same attribute.\u001b[39;00m\n\u001b[1;32m   5586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5587\u001b[0m     \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   5589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:638\u001b[0m, in \u001b[0;36mSeries.name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Hashable:\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m    Return the name of the Series.\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    'Even Numbers'\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:5561\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5557\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mallows_duplicate_labels \u001b[38;5;241m=\u001b[39m allows_duplicate_labels\n\u001b[1;32m   5559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 5561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   5562\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5563\u001b[0m \u001b[38;5;124;03m    After regular attribute access, try looking up the name\u001b[39;00m\n\u001b[1;32m   5564\u001b[0m \u001b[38;5;124;03m    This allows simpler access to columns for interactive use.\u001b[39;00m\n\u001b[1;32m   5565\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   5566\u001b[0m     \u001b[38;5;66;03m# Note: obj.x will always call obj.__getattribute__('x') prior to\u001b[39;00m\n\u001b[1;32m   5567\u001b[0m     \u001b[38;5;66;03m# calling obj.__getattr__('x').\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plotting y ('gpp') against the 'climate' feature\n",
    "sns.boxplot(x=X['climate'], y=y)\n",
    "plt.title('Scatter plot of GPP vs Climate')\n",
    "plt.xlabel('Climate Precipitation')\n",
    "plt.ylabel('GPP (Gross Primary Production)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
